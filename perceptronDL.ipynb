{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 2\n",
    "\n",
    "Implementation of a simple perceptron neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(x):\n",
    "    return torch.tanh(x)\n",
    "\n",
    "def dsigma(x):\n",
    "    return 1 - sigma(x)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(x,t):\n",
    "    return torch.norm(x-t)**2\n",
    "\n",
    "def dloss(x,t):\n",
    "    return 2*(x-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Forward and backward passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:53: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:43: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "from data_MNIST import dlc_practical_prologue as dpp\n",
    "# Load the data\n",
    "train_input, train_target, test_input, test_target = dpp.load_data(one_hot_labels=True,normalize= True)\n",
    "train_target = 0.9*train_target\n",
    "test_target = 0.9*test_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(w1, b1, w2, b2, x):\n",
    "    x0 = x.view(-1,1)\n",
    "    s1 = w1.mm(x0) + b1\n",
    "    x1 = sigma(s1)\n",
    "    s2 = w2.mm(x1) + b2\n",
    "    x2 = sigma(s2)\n",
    "\n",
    "    return x0, s1, x1, s2, x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_pass(w1, b1, w2, b2, t, x, s1, x1, s2, x2,\n",
    "                  dl_dw1, dl_db1, dl_dw2, dl_db2):\n",
    "    \n",
    "    dl_dx2 = dloss(x2,t.view(-1,1))   # (10,1)\n",
    "    dl_ds2 = dl_dx2*dsigma(s2)# (10,1)\n",
    "    dl_dw2 = dl_ds2.mm(x1.view(1,-1)) # (10,50)\n",
    "    dl_db2 = dl_ds2 # (10,1)\n",
    "    dl_dx1 = (w2.t()).mm(dl_ds2) # (50,1)\n",
    "    dl_ds1 = dl_dx1*dsigma(s1) # (50,1)\n",
    "    dl_dw1 = dl_ds1.mm(x.view(1,-1)) # (50,784) \n",
    "    dl_db1 = dl_ds1 # (50,1)\n",
    "    return dl_dw1, dl_db1, dl_dw2, dl_db2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 50\n",
    "epsilon = 1e-6\n",
    "w1 = torch.normal(torch.zeros(n_hidden,train_input.size(1)), epsilon)\n",
    "b1 = torch.normal(torch.zeros(n_hidden,1), epsilon)\n",
    "w2 = torch.normal(torch.zeros(10,50), epsilon)\n",
    "b2 = torch.normal(torch.zeros(10,1), epsilon)\n",
    "\n",
    "dl_dw1 = torch.empty(w1.size())\n",
    "dl_db1 = torch.empty(b1.size())\n",
    "dl_dw2 = torch.empty(w2.size())\n",
    "dl_db2 = torch.empty(b2.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 999: Train_loss 27.200000000000003 %\n",
      "\t : Test_loss 39.300000000000004 %\n",
      "Iter 1999: Train_loss 13.4 %\n",
      "\t : Test_loss 26.3 %\n",
      "Iter 2999: Train_loss 7.9 %\n",
      "\t : Test_loss 22.8 %\n",
      "Iter 3999: Train_loss 6.9 %\n",
      "\t : Test_loss 21.8 %\n",
      "Iter 4999: Train_loss 5.5 %\n",
      "\t : Test_loss 17.4 %\n",
      "Iter 5999: Train_loss 4.2 %\n",
      "\t : Test_loss 16.5 %\n",
      "Iter 6999: Train_loss 3.5999999999999996 %\n",
      "\t : Test_loss 16.5 %\n",
      "Iter 7999: Train_loss 2.5 %\n",
      "\t : Test_loss 16.3 %\n",
      "Iter 8999: Train_loss 2.1 %\n",
      "\t : Test_loss 16.8 %\n",
      "Iter 9999: Train_loss 1.7999999999999998 %\n",
      "\t : Test_loss 16.900000000000002 %\n"
     ]
    }
   ],
   "source": [
    "lr = .01    #Learning rate\n",
    "n_iter = 10000\n",
    "N = train_input.size(0)\n",
    "p = test_input.size(0)\n",
    "for k in range(n_iter):\n",
    "    i = int(torch.randint(0, 1000, (1,)))\n",
    "    x = train_input[i]\n",
    "    t = train_target[i].view(-1,1)\n",
    "    x0, s1, x1, s2, x2 = forward_pass(w1, b1, w2, b2, x)\n",
    "    \n",
    "    dl_dw1, dl_db1, dl_dw2, dl_db2 = backward_pass(w1, b1, w2, b2, t, x0, s1, x1, s2, x2, dl_dw1, dl_db1, dl_dw2, dl_db2)\n",
    "\n",
    "    weights = [w1, b1, w2, b2]\n",
    "    gradient = [dl_dw1, dl_db1, dl_dw2, dl_db2]\n",
    "    w1, b1, w2, b2 = [weights[j]-lr*gradient[j] for j in range(len(weights))]\n",
    "    \n",
    "    if k%1000 == 999:\n",
    "        pred = [torch.argmax(forward_pass(w1, b1, w2, b2,train_input[n])[-1]) for n in range(N)]\n",
    "        targ = [torch.argmax(train_target[n]) for n in range(N)]\n",
    "        loss = ([(pred[l] != targ[l])*1 for l in range(N)].count(1)/N)*100\n",
    "        print(f\"Iter {k}: Train_loss {loss} %\")\n",
    "        \n",
    "        pred_test = [torch.argmax(forward_pass(w1, b1, w2, b2,test_input[n])[-1]) for n in range(p)]\n",
    "        targ_test = [torch.argmax(test_target[n]) for n in range(p)]\n",
    "        loss_test = ([(pred_test[l] != targ_test[l])*1 for l in range(p)].count(1)/p)*100 \n",
    "        print(f\"\\t : Test_loss {loss_test} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dlc_practical_prologue'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5599824a36ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_MNIST\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdlc_practical_4_embryo_modified\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdpe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/aims/ML/NN_1/data_MNIST/dlc_practical_4_embryo_modified.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdlc_practical_prologue\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprologue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_target\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dlc_practical_prologue'"
     ]
    }
   ],
   "source": [
    "from data_MNIST import dlc_practical_4_embryo_modified as dpe\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
